{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"eDnM--CZ1woA","executionInfo":{"status":"ok","timestamp":1758809998009,"user_tz":-300,"elapsed":5499,"user":{"displayName":"Shahram Khalid","userId":"05473135599299348919"}}},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense\n","import re"]},{"cell_type":"code","source":["# Step 1: Prepare Data (Toy Corpus for Next-Word Prediction)\n","# Sentences: Simple dataset including \"Wang loves Noodle\"\n","corpus = [\n","    \"Wang loves Noodle\",\n","    \"I love food\",\n","    \"She eats apple\",\n","    \"She likes music\"\n","]\n","corpus"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i-pg4D-e2Eay","outputId":"b0fbe994-e2d5-4077-bf63-2d0c60927292"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Wang loves Noodle', 'I love food', 'She eats apple', 'She likes music']"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# Tokenize words\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(corpus)\n","vocab_size = len(tokenizer.word_index) + 1  # Vocabulary size (e.g., 10)\n","print(f\"Vocabulary Size: {vocab_size}\")\n","print(\"Word Index:\", tokenizer.word_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6k-WQbZo3f71","outputId":"9f51bee2-2967-4956-edac-203a2abaf36a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary Size: 12\n","Word Index: {'she': 1, 'wang': 2, 'loves': 3, 'noodle': 4, 'i': 5, 'love': 6, 'food': 7, 'eats': 8, 'apple': 9, 'likes': 10, 'music': 11}\n"]}]},{"cell_type":"markdown","source":["This below code creates **n-gram** sequences from each sentence in your corpus, using the indices from your tokenizer.\n","\n","[[2, 3],       # \"Wang loves\"\n","\n"," [2, 3, 4],    # \"Wang loves Noodle\"\n","\n"," [5, 6],       # \"I love\"\n","\n"," [5, 6, 7],    # \"I love food\"\n","\n"," [1, 8],       # \"She eats\"\n","\n"," [1, 8, 9],    # \"She eats apple\"\n","\n"," [1, 10],      # \"She likes\"\n","\n"," [1, 10, 11]]  # \"She likes music\""],"metadata":{"id":"Pm0vCGbB6qr4"}},{"cell_type":"code","source":["# Create sequences: For each sentence, create input (all but last word) and target (next word)\n","sequences = []\n","for sentence in corpus:\n","    tokens = tokenizer.texts_to_sequences([sentence])[0]\n","    for i in range(1, len(tokens)):\n","        sequences.append(tokens[:i+1])  # Input: up to i, Target: i+1 (next word)\n","sequences"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5gtUqH-t334J","outputId":"6ee5b400-7e94-4989-8a0e-0504af5f329e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[2, 3], [2, 3, 4], [5, 6], [5, 6, 7], [1, 8], [1, 8, 9], [1, 10], [1, 10, 11]]"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["Let’s break down below code step by step, why each operation is used, and clarify your confusion at the end.\n","\n","---\n","\n","## **1. Pad Sequences to Fixed Length**\n","\n","```python\n","max_length = max([len(seq) for seq in sequences])\n","X = pad_sequences(sequences, maxlen=max_length, padding='pre')\n","```\n","- **Why pad?**  \n","  Neural networks require all inputs to have the **same length** for batch processing. Sentences (or n-gram sequences) are often different lengths.\n","- **What does `padding='pre'` do?**  \n","  Adds zeros **at the start** of sequences shorter than `max_length`.\n","- **Result:**  \n","  `X` is now a 2D array, each row is a sequence of length `max_length`.\n","\n","---\n","\n","## **2. Create One-Hot Encoded Targets (y)**\n","\n","```python\n","y = to_categorical([seq[-1] for seq in sequences], num_classes=vocab_size)\n","```\n","- **What is this doing?**  \n","  - `seq[-1]` gets the last item in each n-gram sequence: **the next word to predict (the label).**\n","  - `to_categorical` converts these word indices to **one-hot encoded vectors** of length `vocab_size`.\n","    - Example: if `seq[-1] == 4` and `vocab_size == 12`, the vector will be `[0, 0, 0, 1, 0, ..., 0]` (with `1` in position 4).\n","\n","---\n","\n","## **3. Remove Last Word from Input for Prediction**\n","\n","```python\n","X = X[:, :-1]  # Remove last word from input for prediction\n","```\n","- **Why?**  \n","  - Each n-gram sequence looks like `[w1, w2, ..., wn]`.\n","  - The task is: **given [w1, w2, ..., wn-1], predict wn**.\n","  - After padding, the last column is the current target (word to be predicted). So you trim it from the features.\n","- **Result:**  \n","  `X` is now only the input words (not including the prediction/last word in each sequence).\n","\n","---\n","\n","## **4. About the Targets (y)**\n","\n","> y = y[:, :-1]  # Adjust target accordingly? Wait, no: target is the last word of each sequence\n","\n","- **Your Instinct Is Correct:**  \n","  **DO NOT SLICE your target y** like you did with X.\n","  - Targets should stay as the one-hot vectors **representing only the next word**.\n","  - The slicing of X is to ensure that features do not include the word you’re supposed to predict.\n","\n","---\n","\n","## **Putting It All Together**\n","\n","### **Final Shapes and Usage:**\n","\n","- **X shape:** `(num_sequences, max_length - 1)`  \n","  Input: all words in a sequence except the last one (padded in front if needed).\n","- **y shape:** `(num_sequences, vocab_size)`  \n","  Output: one-hot vector representing the correct next word.\n","\n","---\n","\n","## **Diagram**\n","\n","| Sequence         | After Padding | X (input)  | y (target)      |\n","|:-----------------|:-------------|:-----------|:----------------|\n","| [2, 3]           | [0, 2, 3]    | [0, 2]     | one-hot[3]      |\n","| [2, 3, 4]        | [2, 3, 4]    | [2, 3]     | one-hot[4]      |\n","| [5, 6]           | [0, 5, 6]    | [0, 5]     | one-hot[6]      |\n","| ...              | ...          | ...        | ...             |\n","\n","---\n","\n","### **Summary**\n","\n","- **Pad all sequences** to the same length for neural network input.\n","- **X:** all but last word (padded)  \n","- **y:** last word as one-hot vector\n","- **Never slice y** like you do X. Targets should represent only the word you’re trying to predict.\n","\n","---"],"metadata":{"id":"_aSVxuG676QC"}},{"cell_type":"code","source":["# Pad sequences to fixed length (max length here is 3)\n","max_length = max([len(seq) for seq in sequences])\n","X = pad_sequences(sequences, maxlen=max_length, padding='pre')  # Input sequences\n","y = to_categorical([seq[-1] for seq in sequences], num_classes=vocab_size)  # One-hot targets (next word)\n","X = X[:, :-1]  # Remove last word from input for prediction\n","y = y[:, :-1]  # Adjust target accordingly? Wait, no: target is the last word of each sequence"],"metadata":{"id":"Kg-hFTXe6NA7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Corrected: X is all but last, y is last word\n","X = pad_sequences(sequences, maxlen=max_length, padding='pre')[:, :-1]  # Input: sequence without last\n","y = to_categorical([seq[-1] for seq in sequences], num_classes=vocab_size)  # Target: last word"],"metadata":{"id":"VoIf83iu725t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"X Shape: {X.shape}, y Shape: {y.shape}\")\n","print(\"Sample X (sequence):\", X[0])\n","print(\"Sample y (one-hot):\", y[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8wa3KDFI8I0I","outputId":"121a3828-8043-4a4d-d528-a03a9e52ba13"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X Shape: (8, 2), y Shape: (8, 12)\n","Sample X (sequence): [0 2]\n","Sample y (one-hot): [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"]}]},{"cell_type":"code","source":["# Step 2: Build Simple LSTM Network\n","embedding_dim = 300  # Like Word2Vec dimension\n","lstm_units = 128     # Hidden/cell state size"],"metadata":{"id":"jnn4kOsj8MHl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length-1))\n","model.add(LSTM(units=lstm_units, return_sequences=False))  # Single LSTM layer, no return_sequences for final hidden state\n","model.add(Dense(vocab_size, activation='softmax'))  # Output: probability over vocabulary"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BBCrOWpm8ocW","outputId":"4fd00536-e910-4737-f746-648c62aa8898"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","model.build(input_shape=(None, max_length-1))\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":225},"id":"Jx8wh30k8ttF","outputId":"d117cc4d-8daf-409f-d58f-4d416591935a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_2\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │         \u001b[38;5;34m3,600\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m219,648\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │         \u001b[38;5;34m1,548\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,600</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">219,648</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,548</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m224,796\u001b[0m (878.11 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224,796</span> (878.11 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m224,796\u001b[0m (878.11 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224,796</span> (878.11 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["# Step 3: Train the Model\n","model.fit(X, y, epochs=100, batch_size=1, verbose=1)  # Small data, so many epochs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4qhCMe6k9jU6","outputId":"0989894b-92f1-4c60-fde8-611008e8b792"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 2.4903\n","Epoch 2/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8664 - loss: 2.3961\n","Epoch 3/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9722 - loss: 2.3248\n","Epoch 4/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9722 - loss: 2.2389\n","Epoch 5/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9722 - loss: 2.1249\n","Epoch 6/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9722 - loss: 1.9674\n","Epoch 7/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9722 - loss: 1.7487\n","Epoch 8/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9722 - loss: 1.4558 \n","Epoch 9/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9722 - loss: 1.1008 \n","Epoch 10/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9722 - loss: 0.7463 \n","Epoch 11/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9722 - loss: 0.4737 \n","Epoch 12/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9722 - loss: 0.3070\n","Epoch 13/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9722 - loss: 0.2164 \n","Epoch 14/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9286 - loss: 0.1669 \n","Epoch 15/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.1365 \n","Epoch 16/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.1160 \n","Epoch 17/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9286 - loss: 0.1018 \n","Epoch 18/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0920 \n","Epoch 19/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0852 \n","Epoch 20/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0803 \n","Epoch 21/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0765 \n","Epoch 22/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9286 - loss: 0.0735 \n","Epoch 23/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9286 - loss: 0.0711 \n","Epoch 24/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9286 - loss: 0.0692\n","Epoch 25/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0675 \n","Epoch 26/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0662 \n","Epoch 27/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0650 \n","Epoch 28/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9286 - loss: 0.0639 \n","Epoch 29/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0630 \n","Epoch 30/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9286 - loss: 0.0622 \n","Epoch 31/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0615 \n","Epoch 32/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0609 \n","Epoch 33/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0603 \n","Epoch 34/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0598 \n","Epoch 35/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9286 - loss: 0.0593\n","Epoch 36/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0589 \n","Epoch 37/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0585 \n","Epoch 38/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0582 \n","Epoch 39/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0578 \n","Epoch 40/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0575 \n","Epoch 41/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0573 \n","Epoch 42/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0570 \n","Epoch 43/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0568 \n","Epoch 44/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9286 - loss: 0.0565 \n","Epoch 45/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0563 \n","Epoch 46/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0561 \n","Epoch 47/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9286 - loss: 0.0559 \n","Epoch 48/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0558 \n","Epoch 49/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0556 \n","Epoch 50/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0554 \n","Epoch 51/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0553 \n","Epoch 52/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0552 \n","Epoch 53/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0550 \n","Epoch 54/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0549 \n","Epoch 55/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0548 \n","Epoch 56/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0547 \n","Epoch 57/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0546 \n","Epoch 58/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0545 \n","Epoch 59/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9286 - loss: 0.0544 \n","Epoch 60/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0543 \n","Epoch 61/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0542 \n","Epoch 62/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0541 \n","Epoch 63/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0540 \n","Epoch 64/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0539 \n","Epoch 65/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0539 \n","Epoch 66/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0538 \n","Epoch 67/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0537 \n","Epoch 68/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0537 \n","Epoch 69/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0536 \n","Epoch 70/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0535 \n","Epoch 71/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0535 \n","Epoch 72/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0534 \n","Epoch 73/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0534 \n","Epoch 74/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0533 \n","Epoch 75/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0533 \n","Epoch 76/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0532 \n","Epoch 77/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0532 \n","Epoch 78/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0531 \n","Epoch 79/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0531 \n","Epoch 80/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0530 \n","Epoch 81/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0530 \n","Epoch 82/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9286 - loss: 0.0529 \n","Epoch 83/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0529 \n","Epoch 84/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0529 \n","Epoch 85/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9286 - loss: 0.0528 \n","Epoch 86/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0528 \n","Epoch 87/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0527     \n","Epoch 88/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0527     \n","Epoch 89/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0527     \n","Epoch 90/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0526     \n","Epoch 91/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0526     \n","Epoch 92/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0526     \n","Epoch 93/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0526     \n","Epoch 94/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9286 - loss: 0.0525\n","Epoch 95/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0525     \n","Epoch 96/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0525     \n","Epoch 97/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0524     \n","Epoch 98/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0524     \n","Epoch 99/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0524     \n","Epoch 100/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.0524     \n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7fac93ddd2e0>"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["# Step 4: Autocomplete Function (Generate Next Word)\n","def autocomplete(seed_text, tokenizer, model, max_length, num_words=1):\n","    for _ in range(num_words):\n","        # Tokenize seed\n","        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n","        # Pad\n","        token_list = pad_sequences([token_list], maxlen=max_length-1, padding='pre')\n","        # Predict\n","        predicted = model.predict(token_list, verbose=0)\n","        predicted_word_index = np.argmax(predicted)\n","        # Find word\n","        word = ''\n","        for key, value in tokenizer.word_index.items():\n","            if value == predicted_word_index:\n","                word = key\n","                break\n","        # Append and update seed\n","        seed_text += \" \" + word\n","    return seed_text"],"metadata":{"id":"Cq-Y6sgsAQu6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example Usage\n","seed = \"Wang loves\"\n","predicted = autocomplete(seed, tokenizer, model, max_length)\n","print(f\"Autocomplete for '{seed}': {predicted}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k9vrdgdbAZ9j","outputId":"777b0a03-676c-46af-8d79-523225bed634"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Autocomplete for 'Wang loves': Wang loves noodle\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Yu1rHLUcAjV9"},"execution_count":null,"outputs":[]}]}